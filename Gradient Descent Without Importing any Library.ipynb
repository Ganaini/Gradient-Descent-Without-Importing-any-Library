{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa915cc6",
   "metadata": {},
   "source": [
    "# Gradient Descent Without Importing any Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005501a6",
   "metadata": {},
   "source": [
    "### Here, we perform basic Gradient Descent without using numpy or pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0b7457",
   "metadata": {},
   "source": [
    "#### We use a single function, <i>y</i> = 3<i>x</i> for ease, where <i>y</i> and <i>x</i> are vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2ad2ef",
   "metadata": {},
   "source": [
    "#### We create two lists representing an input and the expected output to fulfill the previous function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbcab83",
   "metadata": {},
   "source": [
    "#### As we are not using numpt or pytorch, we use lists to represent the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29965c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,2,3,4]  # Input vector\n",
    "y = [3,6,9,12]  # Expected output vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33382811",
   "metadata": {},
   "source": [
    "#### As we cannot make a dot product between two lists, we create the following helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70a8b4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(a, b):\n",
    "    ans = []\n",
    "    for i, j in zip(a, b):\n",
    "        ans.append(i*j)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cfe488",
   "metadata": {},
   "source": [
    "#### Let's set the initial weight value to 0.1. Note that the target after training the model is 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2b853dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aefa3d",
   "metadata": {},
   "source": [
    "#### A function to perform the forward propagation. It accepts the input list and return the predicted output y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50fd3a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    y_hat = [w*e for e in x]\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df8cf66",
   "metadata": {},
   "source": [
    "#### A function to calculate and return the mean square error loss by comparing the predicted output and the target output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16737012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y_pred, y):\n",
    "    SE = []  ## First calculate square error\n",
    "    for i, j in zip(y_pred, y):\n",
    "        SE.append((i-j)**2)\n",
    "    MSE = sum(SE) / len(SE)\n",
    "    return MSE    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9edcaa5",
   "metadata": {},
   "source": [
    "#### The gradient function calculates the partial derivative of the loss with respect to the weight. \n",
    "#### To calculate that, we first claculate the partial derivative of the loss with respect to predicted output and multiply it by the partial derivative of the predicted output with respect to the weight. (Check the partial derivative chain rule: https://tutorial.math.lamar.edu/classes/calciii/chainrule.aspx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1bb52aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(y_pred, y, x):\n",
    "    # The returned gradient = mean(2 * x * (y_pred - y))\n",
    "    # We implement the previous function as follows:\n",
    "    first_part = 2 * [2*e for e in x]  # 2 * x\n",
    "    diff = []  # (y_pred - y)\n",
    "    for i, j in zip(y_pred, y):\n",
    "        diff.append(i-j)\n",
    "    gr = dot_product(first_part, diff)  # 2 * x * (y_pred - y)\n",
    "    gr = sum(gr) / len(gr)  # mean(2 * x * (y_pred - y))\n",
    "    return gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4a1539",
   "metadata": {},
   "source": [
    "#### We set the number of iterations to improve the weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79d32706",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c792319",
   "metadata": {},
   "source": [
    "#### The step to update the weight, try different ones and see the difference.\n",
    "#### Note that if the step is so big, the model will not learn and the weight will keep changing drastically (try lr=1)\n",
    "#### Note that if the step is so small, the model will need more epochs to converge (try lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6d24c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4beabe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 63.074999999999996, weight: 0.535\n",
      "Epoch: 1, loss: 45.571687499999996, weight: 0.9047499999999999\n",
      "Epoch: 2, loss: 32.925544218750005, weight: 1.2190375\n",
      "Epoch: 3, loss: 23.788705698046876, weight: 1.486181875\n",
      "Epoch: 4, loss: 17.18733986683887, weight: 1.7132545937499999\n",
      "Epoch: 5, loss: 12.417853053791083, weight: 1.9062664046875\n",
      "Epoch: 6, loss: 8.971898831364058, weight: 2.070326443984375\n",
      "Epoch: 7, loss: 6.482196905660529, weight: 2.209777477386719\n",
      "Epoch: 8, loss: 4.683387264339732, weight: 2.328310855778711\n",
      "Epoch: 9, loss: 3.3837472984854555, weight: 2.4290642274119043\n",
      "Epoch: 10, loss: 2.4447574231557434, weight: 2.514704593300119\n",
      "Epoch: 11, loss: 1.7663372382300224, weight: 2.587498904305101\n",
      "Epoch: 12, loss: 1.2761786546211908, weight: 2.649374068659336\n",
      "Epoch: 13, loss: 0.9220390779638108, weight: 2.7019679583604357\n",
      "Epoch: 14, loss: 0.6661732338288526, weight: 2.7466727646063704\n",
      "Epoch: 15, loss: 0.4813101614413452, weight: 2.784671849915415\n",
      "Epoch: 16, loss: 0.34774659164137256, weight: 2.8169710724281027\n",
      "Epoch: 17, loss: 0.2512469124608912, weight: 2.844425411563887\n",
      "Epoch: 18, loss: 0.18152589425299398, weight: 2.8677615998293042\n",
      "Epoch: 19, loss: 0.131152458597788, weight: 2.8875973598549085\n",
      "Epoch: 20, loss: 0.09475765133690192, weight: 2.904457755876672\n",
      "Epoch: 21, loss: 0.06846240309091173, weight: 2.9187890924951714\n",
      "Epoch: 22, loss: 0.04946408623318367, weight: 2.9309707286208955\n",
      "Epoch: 23, loss: 0.03573780230347545, weight: 2.941325119327761\n",
      "Epoch: 24, loss: 0.025820562164261165, weight: 2.950126351428597\n",
      "Epoch: 25, loss: 0.01865535616367866, weight: 2.9576073987143072\n",
      "Epoch: 26, loss: 0.013478494828257907, weight: 2.963966288907161\n",
      "Epoch: 27, loss: 0.00973821251341641, weight: 2.9693713455710866\n",
      "Epoch: 28, loss: 0.007035858540943485, weight: 2.973965643735424\n",
      "Epoch: 29, loss: 0.005083407795831576, weight: 2.97787079717511\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    y_pred = model(x)  # Use the model function and pass the input tor predict the output\n",
    "    l = loss(y_pred, y)  # Calculate the loss\n",
    "    dw = gradient(y_pred, y, x) # calculate the gradient\n",
    "    w -= dw * lr  # Update the weight\n",
    "    print(f\"Epoch: {epoch}, loss: {l}, weight: {w}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef37454",
   "metadata": {},
   "source": [
    "## Now we can see that the model converged succesfully and the weight became very close to 3 as targeted. More epochs should make better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5e04a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
